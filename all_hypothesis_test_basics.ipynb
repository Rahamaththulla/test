{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPWWcuoRr5fKCpIzwkj0e+1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rahamaththulla/test/blob/main/all_hypothesis_test_basics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "KCcHGzw6dErH"
      },
      "outputs": [],
      "source": [
        "\n",
        "synchronous = [94. , 84.9, 82.6, 69.5, 80.1, 79.6, 81.4, 77.8, 81.7, 78.8, 73.2, 87.9, 87.9, 93.5, 82.3, 79.3, 78.3, 71.6, 88.6, 74.6, 74.1, 80.6]\n",
        "\n",
        "asynchronous = [77.1, 71.7, 91. , 72.2, 74.8, 85.1, 67.6, 69.9, 75.3, 71.7, 65.7, 72.6, 71.5, 78.2]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def check_normality(data):\n",
        "    import scipy.stats as stats\n",
        "    statistic_value,p_value=stats.shapiro(data)\n",
        "    print(\"p_value :%0.4f\"% p_value)\n",
        "    if(p_value>0.05):\n",
        "        print(\"Fail to reject null hypothesis >> The data is normally distributed\")\n",
        "    else:\n",
        "        print(\"Reject null hypothesis >> The data is not normally distributed\")\n",
        "     "
      ],
      "metadata": {
        "id": "VIFBwjRdp-dw"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "synchronous = [94. , 84.9, 82.6, 69.5, 80.1, 79.6, 81.4, 77.8, 81.7, 78.8, 73.2, 87.9, 87.9, 93.5, 82.3, 79.3, 78.3, 71.6, 88.6, 74.6, 74.1, 80.6]\n",
        "asynchronous = [77.1, 71.7, 91. , 72.2, 74.8, 85.1, 67.6, 69.9, 75.3, 71.7, 65.7, 72.6, 71.5, 78.2]\n",
        "check_normality(synchronous)\n",
        "check_normality(asynchronous)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jXtTjzxRr6oA",
        "outputId": "d27cbb72-5406-4d83-f544-d8a53bd0ad1e"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p_value :0.6556\n",
            "Fail to reject null hypothesis >> The data is normally distributed\n",
            "p_value :0.0803\n",
            "Fail to reject null hypothesis >> The data is normally distributed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def homogeneous_test(group1,group2):\n",
        "  import scipy.stats as stats\n",
        "  statistic_value,pvalue=stats.levene(group1,group2)\n",
        "  print(\"p_value:%0.8f\"%pvalue)\n",
        "  if(pvalue>0.05):\n",
        "    return(\"Fail to reject null hypothesis >> The variances of the samples are same\")\n",
        "  else:\n",
        "    return(\"Reject null hypothesis >> The variances of the samples are different\")\n"
      ],
      "metadata": {
        "id": "0DdtlHvlu2xx"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "synchronous = [94. , 84.9, 82.6, 69.5, 80.1, 79.6, 81.4, 77.8, 81.7, 78.8, 73.2, 87.9, 87.9, 93.5, 82.3, 79.3, 78.3, 71.6, 88.6, 74.6, 74.1, 80.6]\n",
        "asynchronous = [77.1, 71.7, 91. , 72.2, 74.8, 85.1, 67.6, 69.9, 75.3, 71.7, 65.7, 72.6, 71.5, 78.2]\n",
        "print(homogeneous_test(synchronous,asynchronous))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12w8BJMtwBla",
        "outputId": "d9a8d805-404d-4b26-9728-8f076b482d4e"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p_value:0.81489841\n",
            "Fail to reject null hypothesis >> The variances of the samples are same\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def final_testing(group1,group2):\n",
        "  import scipy.stats as stats\n",
        "  statistics_value,p_value=stats.ttest_ind(group1,group2)\n",
        "  print(\"p_value:%0.6f\"%p_value)\n",
        "  if(p_value>0.05):\n",
        "    print(\"fail to reject Ho >> independent sample\")\n",
        "  else:\n",
        "    print(\"Reject Ho >> dependent\")  \n",
        "  "
      ],
      "metadata": {
        "id": "8w5cdLAIy9Ae"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "synchronous = [94. , 84.9, 82.6, 69.5, 80.1, 79.6, 81.4, 77.8, 81.7, 78.8, 73.2, 87.9, 87.9, 93.5, 82.3, 79.3, 78.3, 71.6, 88.6, 74.6, 74.1, 80.6]\n",
        "asynchronous = [77.1, 71.7, 91. , 72.2, 74.8, 85.1, 67.6, 69.9, 75.3, 71.7, 65.7, 72.6, 71.5, 78.2]\n",
        "final_testing(synchronous,asynchronous)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5aZvr6gg08aX",
        "outputId": "da16b68d-a0c0-4ccb-f381-a5a046c363f5"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p_value:0.007536\n",
            "Reject Ho >> dependent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#A pediatrician wants to see the effect of formula consumption on the average monthly weight gain (in gr) of babies. For this reason, she collected data from three different groups. The first group is exclusively breastfed children (receives only breast milk), the second group is children who are fed with only formula and the last group is both formula and breastfed children. These data are as below.\n",
        "\n",
        "only_breast=[794.1, 716.9, 993. , 724.7, 760.9, 908.2, 659.3 , 690.8, 768.7, 717.3 , 630.7, 729.5, 714.1, 810.3, 583.5, 679.9, 865.1]\n",
        "\n",
        "only_formula=[ 898.8, 881.2, 940.2, 966.2, 957.5, 1061.7, 1046.2, 980.4, 895.6, 919.7, 1074.1, 952.5, 796.3, 859.6, 871.1 , 1047.5, 919.1 , 1160.5, 996.9]\n",
        "\n",
        "both=[976.4, 656.4, 861.2, 706.8, 718.5, 717.1, 759.8, 894.6, 867.6, 805.6, 765.4, 800.3, 789.9, 875.3, 740. , 799.4, 790.3, 795.2 , 823.6, 818.7, 926.8, 791.7, 948.3]\n",
        "\n",
        "#According to this information, conduct the hypothesis testing to check whether there is a difference between the average monthly gain of these three groups by using a 0.05 significance level. If there is a significant difference, perform further analysis to find what caused the difference. Before doing hypothesis testing, check the related assumptions.\n",
        "\n",
        "##H₀: μ₁=μ₂=μ₃ or The mean of the samples is the same.\n",
        "#H₁: At least one of them is different.\n",
        "#Assumption Check\n",
        "#H₀: The data is normally distributed.\n",
        "\n",
        "#(H₁: The data is not normally distributed.\n",
        "\n",
        "#Check 2\n",
        "\n",
        "#H₀: The variances of the samples are the same.\n",
        "\n",
        "#H₁: The variances of the samples are different.)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "yBI0jD7BHqyO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "only_breast=[794.1, 716.9, 993. , 724.7, 760.9, 908.2, 659.3 , 690.8, 768.7, 717.3 , 630.7, 729.5, 714.1, 810.3, 583.5, 679.9, 865.1]\n",
        "\n",
        "only_formula=[ 898.8, 881.2, 940.2, 966.2, 957.5, 1061.7, 1046.2, 980.4, 895.6, 919.7, 1074.1, 952.5, 796.3, 859.6, 871.1 , 1047.5, 919.1 , 1160.5, 996.9]\n",
        "\n",
        "both=[976.4, 656.4, 861.2, 706.8, 718.5, 717.1, 759.8, 894.6, 867.6, 805.6, 765.4, 800.3, 789.9, 875.3, 740. , 799.4, 790.3, 795.2 , 823.6, 818.7, 926.8, 791.7, 948.3]"
      ],
      "metadata": {
        "id": "CqZVurEFGsG1"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "check_normality(only_breast)\n",
        "check_normality(only_formula)\n",
        "check_normality(both)\n",
        "import scipy.stats as stats\n",
        "stat, pvalue_levene= stats.levene(only_breast,only_formula,both)\n",
        "print(\"p value:%.4f\" % pvalue_levene)\n",
        "if pvalue_levene <0.05:\n",
        "    print(\"Reject null hypothesis >> The variances of the samples are different.\")\n",
        "else:\n",
        "    print(\"Fail to reject null hypothesis >> The variances of the samples are same.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65_OYsbfG6yN",
        "outputId": "46233e81-b907-4d7d-b162-26cca3ac1720"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p_value :0.4694\n",
            "Fail to reject null hypothesis >> The data is normally distributed\n",
            "p_value :0.8879\n",
            "Fail to reject null hypothesis >> The data is normally distributed\n",
            "p_value :0.7973\n",
            "Fail to reject null hypothesis >> The data is normally distributed\n",
            "p value:0.7673\n",
            "Fail to reject null hypothesis >> The variances of the samples are same.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "F,p = stats.f_oneway(only_breast,only_formula,both)\n",
        "print(p)\n",
        "if p <0.05:\n",
        "    print(\"Reject null hypothesis\")\n",
        "else:\n",
        "    print(\"Fail to reject null hypothesis\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLhj3S3iG_RX",
        "outputId": "1d29412f-1d0b-4af3-de78-97bdf8fd9764"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7.18623550288582e-09\n",
            "Reject null hypothesis\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##A human resource specialist working in a technology company is interested in the overwork time of different teams. To investigate whether there is a difference between overtime of the software development team and the test team, she selected 17 employees randomly in each of the two teams and recorded their weekly average overwork time in terms of an hour. The data is below.\n",
        "\n",
        "test_team=[6.2, 7.1, 1.5, 2,3 , 2, 1.5, 6.1, 2.4, 2.3, 12.4, 1.8, 5.3, 3.1, 9.4, 2.3, 4.1] developer_team=[2.3, 2.1, 1.4, 2.0, 8.7, 2.2, 3.1, 4.2, 3.6, 2.5, 3.1, 6.2, 12.1, 3.9, 2.2, 1.2 ,3.4]\n",
        "\n",
        "#According to this information, conduct the hypothesis testing to check whether there is a difference between the overwork time of two teams by using a 0.05 significance level. Before doing hypothesis testing, check the related assumptions.\n",
        "\n",
        "#Defining Hypothesis\n",
        "#H₀: μ₁≤μ₂\n",
        "#H₁: μ₁>μ₂\n",
        "#Assumption Check\n",
        "#H₀: The data is normally distributed.\n",
        "#H₁: The data is not normally distributed.\n",
        "#H₀: The variances of the samples are the same.\n",
        "#H₁: The variances of the samples are different.\n"
      ],
      "metadata": {
        "id": "nvwFrZEmISQo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_team=[6.2, 7.1, 1.5, 2,3 , 2, 1.5, 6.1, 2.4, 2.3, 12.4, 1.8, 5.3, 3.1, 9.4, 2.3, 4.1]\n",
        "developer_team=[2.3, 2.1, 1.4, 2.0, 8.7, 2.2, 3.1, 4.2, 3.6, 2.5, 3.1, 6.2, 12.1, 3.9, 2.2, 1.2 ,3.4]\n",
        "\n",
        "check_normality(test_team)\n",
        "check_normality(developer_team)\n",
        "homogeneous_test(test_team, developer_team)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "UcnGm_jDIxes",
        "outputId": "8481f88b-7118-4c8d-951b-4d1a43b958d9"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p_value :0.0046\n",
            "Reject null hypothesis >> The data is not normally distributed\n",
            "p_value :0.0005\n",
            "Reject null hypothesis >> The data is not normally distributed\n",
            "p_value:0.54095578\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Fail to reject null hypothesis >> The variances of the samples are same'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Selecting the Proper Test\n",
        "#There are two groups, and data is collected from different individuals, so it is not paired. However, the normality assumption is not satisfied; therefore, we need to use the nonparametric version of 2 group comparison for unpaired data: the Mann-Whitney U Test.\n",
        "\n",
        "ttest,pvalue = stats.mannwhitneyu(test_team,developer_team, alternative=\"two-sided\")\n",
        "print(\"p-value:%.4f\" % pvalue)\n",
        "if pvalue <0.05:\n",
        "    print(\"Reject null hypothesis\")\n",
        "else:\n",
        "    print(\"Fail to reject null hypothesis\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9GznFuquJL6c",
        "outputId": "61294cd6-b705-444d-dc5e-230a8be012a5"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p-value:0.8226\n",
            "Fail to reject null hypothesis\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Kruskal-Wallis\n",
        "An e-commerce company regularly advertises on YouTube, Instagram, and Facebook for its campaigns. However, the new manager was curious about if there was any difference between the number of customers attracted by these platforms. Therefore, she started to use Adjust, an application that allows you to find out where your users come from. The daily numbers reported from Adjust for each platform are as below.\n",
        "\n",
        "Youtube=[1913, 1879, 1939, 2146, 2040, 2127, 2122, 2156, 2036, 1974, 1956, 2146, 2151, 1943, 2125]\n",
        "\n",
        "Instagram = [2305., 2355., 2203., 2231., 2185., 2420., 2386., 2410., 2340., 2349., 2241., 2396., 2244., 2267., 2281.]\n",
        "\n",
        "Facebook = [2133., 2522., 2124., 2551., 2293., 2367., 2460., 2311., 2178., 2113., 2048., 2443., 2265., 2095., 2528.]\n",
        "\n",
        "According to this information, conduct the hypothesis testing to check whether there is a difference between the average customer acquisition of these three platforms using a 0.05 significance level. If there is a significant difference, perform further analysis to find that caused the difference. Before doing hypothesis testing, check the related assumptions.\n",
        "\n",
        "Defining Hypothesis\n",
        "H₀: μ₁=μ₂=μ₃ or The mean of the samples is the same.\n",
        "H₁: At least one of them is different.\n",
        "Assumption Check\n",
        "H₀: The data is normally distributed.\n",
        "H₁: The data is not normally distributed.\n",
        "H₀: The variances of the samples are the same.\n",
        "H₁: The variances of the samples are different.\n",
        "[ ]\n",
        "youtube=[1913, 1879, 1939, 2146, 2040, 2127, 2122, 2156, 2036, 1974, 1956, 2146, 2151, 1943, 2125]\n",
        "\n",
        "\n",
        "instagram = [2305., 2355., 2203., 2231., 2185., 2420., 2386., 2410., 2340., 2349., 2241., 2396., 2244., 2267., 2281.]\n",
        "\n",
        "\n",
        "facebook = [2133., 2522., 2124., 2551., 2293., 2367., 2460., 2311., 2178., 2113., 2048., 2443., 2265., 2095., 2528.]\n",
        "\n",
        "check_normality(youtube)\n",
        "check_normality(instagram)\n",
        "\n",
        "p value:0.0285\n",
        "Reject null hypothesis >> The data is not normally distributed\n",
        "p value:0.4156\n",
        "Fail to reject null hypothesis >> The data is normally distributed\n",
        "p value:0.1716\n",
        "Fail to reject null hypothesis >> The data is normally distributed\n",
        "p value:0.0012\n",
        "Reject null hypothesis >> The variances of the samples are different.\n",
        "[ ]\n",
        "F, p_value = stats.kruskal(youtube, instagram, facebook)\n",
        "print(\"p value:%.6f\" % p_value)\n",
        "if p_value <0.05:\n",
        "    print(\"Reject null hypothesis\")\n",
        "else:\n",
        "    print(\"Fail to reject null hypothesis\")\n",
        "p value:0.000015\n",
        "Reject null hypothesis\n",
        "At this significance level, at least one of the average customer acquisition number is different.\n",
        "\n",
        "Note: Since the data is not normal, the nonparametric version of posthoc test is used.\n",
        "\n",
        "[ ]\n",
        "posthoc_df = sp.posthoc_mannwhitney([youtube,instagram, facebook], p_adjust = 'bonferroni')\n",
        "group_names= [\"youtube\", \"instagram\",\"facebook\"]\n",
        "posthoc_df.columns= group_names\n",
        "posthoc_df.index= group_names\n",
        "posthoc_df.style.applymap (lambda x: \"background-color:violet\" if x<0.05 else \"background-color: white\")\n",
        "\n",
        "\n",
        "The average number of customers coming from YouTube is different than the other (actually smaller than the others).\n",
        "\n",
        "t-test dependent\n",
        "The University Health Center diagnosed eighteen students with high cholesterol in the previous semester. Healthcare personnel told these patients about the dangers of high cholesterol and prescribed a diet program. One month later, the patients came for control, and their cholesterol level was reexamined. Test whether there is a difference in the cholesterol levels of the patients.\n",
        "\n",
        "According to this information, conduct the hypothesis testing to check whether there is a decrease in the cholesterol levels of the patients after the diet by using a 0.05 significance level. Before doing hypothesis testing, check the related assumptions. Comment on the results\n",
        "\n",
        "test_results_before_diet=[224, 235, 223, 253, 253, 224, 244, 225, 259, 220, 242, 240, 239, 229, 276, 254, 237, 227] test_results_after_diet=[198, 195, 213, 190, 246, 206, 225, 199, 214, 210, 188, 205, 200, 220, 190, 199, 191, 218]\n",
        "\n",
        "Defining Hypothesis\n",
        "H₀: μd>=0 or The true mean difference is equal to or bigger than zero.\n",
        "H₁: μd < 0 or The true mean difference is smaller than zero.\n",
        "Assumption Check\n",
        "The dependent variable must be continuous (interval/ratio)\n",
        "The observations are independent of one another.\n",
        "The dependent variable should be approximately normally distributed.\n",
        "H₀: The data is normally distributed.\n",
        "H₁: The data is not normally distributed.\n",
        "[ ]\n",
        "test_results_before_diet=[224, 235, 223, 253, 253, 224, 244, 225, 259, 220, 242, 240, 239, 229, 276, 254, 237, 227]\n",
        "test_results_after_diet=[198, 195, 213, 190, 246, 206, 225, 199, 214, 210, 188, 205, 200, 220, 190, 199, 191, 218]\n",
        "\n",
        "check_normality(test_results_before_diet)\n",
        "check_normality(test_results_after_diet)\n",
        "p value:0.1635\n",
        "Fail to reject null hypothesis >> The data is normally distributed\n",
        "p value:0.1003\n",
        "Fail to reject null hypothesis >> The data is normally distributed\n",
        "Selecting the Proper Test\n",
        "The data is paired since data is collected from the same individuals and assumptions are satisfied, then we can use the dependent t-test.\n",
        "\n",
        "[ ]\n",
        "test_stat, p_value_paired = stats.ttest_rel(test_results_before_diet,test_results_after_diet)\n",
        "print(\"p value:%.6f\" % p_value_paired , \"one tailed p value:%.6f\" %(p_value_paired/2))\n",
        "if p_value_paired <0.05:\n",
        "    print(\"Reject null hypothesis\")\n",
        "else:\n",
        "    print(\"Fail to reject null hypothesis\")\n",
        "p value:0.000008 one tailed p value:0.000004\n",
        "Reject null hypothesis\n",
        "Decision and Conclusion\n",
        "\n",
        "At this significance level, there is enough evidence to conclude mean cholesterol level of patients has decreased after the diet.\n",
        "\n",
        "Wilcoxon signed-rank test\n",
        "A venture capitalist wanted to invest in a startup that provides data compression without any loss in quality, but there are two competitors: PiedPiper and EndFrame. Initially, she believed the performance of the EndFrame could be better but still wanted to test it before the investment. Then, she gave the same files to each company to compress and recorded their performance scores. The data is below.\n",
        "\n",
        "piedpiper=[4.57, 4.55, 5.47, 4.67, 5.41, 5.55, 5.53, 5.63, 3.86, 3.97, 5.44, 3.93, 5.31, 5.17, 4.39, 4.28, 5.25] endframe = [4.27, 3.93, 4.01, 4.07, 3.87, 4. , 4. , 3.72, 4.16, 4.1 , 3.9 , 3.97, 4.08, 3.96, 3.96, 3.77, 4.09]\n",
        "\n",
        "According to this information, conduct the related hypothesis testing by using a 0.05 significance level. Before doing hypothesis testing, check the related assumptions. Comment on the results.\n",
        "\n",
        "Defining Hypothesis Since the performance scores are obtained from the same files, the data is paired.\n",
        "H₀: μd>=0 or The true mean difference is equal to or bigger than zero.\n",
        "H₁: μd < 0 or The true mean difference is smaller than zero.\n",
        "Assumption Check\n",
        "The dependent variable must be continuous (interval/ratio)\n",
        "The observations are independent of one another.\n",
        "The dependent variable should be approximately normally distributed.\n",
        "H₀: The data is normally distributed.\n",
        "H₁: The data is not normally distributed.\n",
        "[ ]\n",
        "piedpiper=[4.57, 4.55, 5.47, 4.67, 5.41, 5.55, 5.53, 5.63, 3.86, 3.97, 5.44, 3.93, 5.31, 5.17, 4.39, 4.28, 5.25]\n",
        "endframe = [4.27, 3.93, 4.01, 4.07, 3.87, 4. , 4. , 3.72, 4.16, 4.1 , 3.9 , 3.97, 4.08, 3.96, 3.96, 3.77, 4.09]\n",
        "\n",
        "check_normality(piedpiper)\n",
        "check_normality(endframe)\n",
        "p value:0.0304\n",
        "Reject null hypothesis >> The data is not normally distributed\n",
        "p value:0.9587\n",
        "Fail to reject null hypothesis >> The data is normally distributed\n",
        "Selecting the Proper Test\n",
        "The normality assumption is not satisfied; therefore, we need to use the nonparametric version of the paired test, namely the Wilcoxon Signed Rank test.\n",
        "\n",
        "[ ]\n",
        "test,pvalue = stats.wilcoxon(endframe,piedpiper) ##alternative default two sided\n",
        "print(\"p-value:%.6f\" %pvalue, \">> one_tailed_pval:%.6f\" %(pvalue/2))\n",
        "\n",
        "test,one_sided_pvalue = stats.wilcoxon(endframe,piedpiper, alternative=\"less\")\n",
        "print(\"one sided pvalue:%.6f\" %(one_sided_pvalue))\n",
        "if pvalue <0.05:\n",
        "    print(\"Reject null hypothesis\")\n",
        "else:\n",
        "    print(\"Fail to recejt null hypothesis\")\n",
        "p-value:0.000214 >> one_tailed_pval:0.000107\n",
        "one sided pvalue:0.000107\n",
        "Reject null hypothesis\n",
        "At this significance level, there is enough evidence to conclude that the performance of the PiedPaper is better than the EndFrame.\n",
        "\n",
        "Friedman Chi-Square\n",
        "A researcher was curious about whether there is a difference between the methodology she developed, C, and baseline methods A and B in terms of performance. Therefore, she decided to design different experiments and recorded the achieved accuracy by each method. The below table shows the achieved accuracy on test sets by each method. Please note that the same train and test sets were used for each method.\n",
        "\n",
        "image.png\n",
        "\n",
        "According to this information, conduct the hypothesis testing to check whether there is a difference between the performance of the methods by using a 0.05 significance level. If there is a significant difference, perform further analysis to find which one caused the difference. Before doing hypothesis testing, check the related assumptions. Comment on the results.\n",
        "\n",
        "Defining Hypothesis\n",
        "H₀: μ₁=μ₂=μ₃ or The mean of the samples is the same.\n",
        "H₁: At least one of them is different.\n",
        "Assumption Check\n",
        "H₀: The data is normally distributed.\n",
        "H₁: The data is not normally distributed.\n",
        "H₀: The variances of the samples are the same.\n",
        "\n",
        "H₁: The variances of the samples are different.\n",
        "\n",
        "[ ]\n",
        "method_A=[89.8,89.9,88.6,88.7,89.6,89.7,89.2,89.3]\n",
        "method_B=[90.0,90.1,88.8,88.9,89.9,90.0,89.0,89.2]\n",
        "method_C=[91.5,90.7,90.3,90.4,90.2,90.3,90.2,90.3]\n",
        "check_normality(method_A)\n",
        "check_normality(method_B)\n",
        "check_normality(method_C)\n",
        "\n",
        "print(\"p value:%.4f\" % pvalue_levene)\n",
        "if pvalue_levene <0.05:\n",
        "    print(\"Reject null hypothesis >> The variances of the samples are different.\")\n",
        "else:\n",
        "    print(\"Fail to reject null hypothesis >> The variances of the samples are same.\")\n",
        "p value:0.3076\n",
        "Fail to reject null hypothesis >> The data is normally distributed\n",
        "p value:0.0515\n",
        "Fail to reject null hypothesis >> The data is normally distributed\n",
        "p value:0.0016\n",
        "Reject null hypothesis >> The data is not normally distributed\n",
        "p value:0.0012\n",
        "Reject null hypothesis >> The variances of the samples are different.\n",
        "Selecting the Proper Test\n",
        "There are three groups, but the normality assumption is violated. So, we need to use the nonparametric version of ANOVA for paired data since the accuracy scores are obtained from the same test sets.\n",
        "\n",
        "[ ]\n",
        "test_stat,p_value = stats.friedmanchisquare(method_A,method_B, method_C)\n",
        "print(\"p value:%.4f\" % p_value)\n",
        "if p_value <0.05:\n",
        "    print(\"Reject null hypothesis\")\n",
        "else:\n",
        "    print(\"Fail to reject null hypothesis\")\n",
        "    \n",
        "print(np.round(np.mean(method_A),2), np.round(np.mean(method_B),2), np.round(np.mean(method_C),2))\n",
        "\n",
        "p value:0.0015\n",
        "Reject null hypothesis\n",
        "89.35 89.49 90.49\n",
        "Decison and conclusion\n",
        "\n",
        "At this significance level, at least one of the methods has a different performance.\n",
        "\n",
        "[ ]\n",
        "data = np.array([method_A, method_B, method_C]) \n",
        "posthoc_df=sp.posthoc_wilcoxon(data, p_adjust=\"holm\")\n",
        "# posthoc_df = sp.posthoc_nemenyi_friedman(data.T) ## another option for the posthoc test\n",
        "\n",
        "group_names= [\"Method A\", \"Method B\",\"Method C\"]\n",
        "posthoc_df.columns= group_names\n",
        "posthoc_df.index= group_names\n",
        "posthoc_df.style.applymap(lambda x: \"background-color:violet\" if x<0.05 else \"background-color: white\")\n",
        "\n",
        "\n",
        "Method C outperformed others and achieved better accuracy scores than the others.\n",
        "\n",
        "The goodness of Fit\n",
        "An analyst of a financial investment company is curious about the relationship between gender and risk appetite. A random sample was taken of 660 customers from the database. The customers in the sample were classified according to their gender and their risk appetite. The result is given in the following table.\n",
        "\n",
        "image.png\n",
        "\n",
        "Test the hypothesis that the risk appetite of the customers in this company is independent of their gender. Use α = 0.01.\n",
        "\n",
        "Defining Hypothesis\n",
        "H₀: Gender and risk appetite are independent.\n",
        "\n",
        "H₁: Gender and risk appetite are dependent.\n",
        "\n",
        "Selecting the Proper Test and Assumption Check chi2 test should be used for this question. This test is known as the goodness-of-fit test. It implies that if the observed data are very close to the expected data.\n",
        "\n"
      ],
      "metadata": {
        "id": "Ps8e2a20asTc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "youtube=[1913, 1879, 1939, 2146, 2040, 2127, 2122, 2156, 2036, 1974, 1956, 2146, 2151, 1943, 2125]\n",
        "\n",
        "\n",
        "instagram = [2305., 2355., 2203., 2231., 2185., 2420., 2386., 2410., 2340., 2349., 2241., 2396., 2244., 2267., 2281.]\n",
        "\n",
        "\n",
        "facebook = [2133., 2522., 2124., 2551., 2293., 2367., 2460., 2311., 2178., 2113., 2048., 2443., 2265., 2095., 2528.]"
      ],
      "metadata": {
        "id": "ZxYrowACa_oL"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "check_normality(youtube)\n",
        "check_normality(instagram)\n",
        "check_normality(facebook)\n",
        "import scipy.stats as stats\n",
        "\n",
        "stat, pvalue_levene= stats.levene(youtube, instagram, facebook)\n",
        "\n",
        "print(\"p value:%.4f\" % pvalue_levene)\n",
        "if pvalue_levene <0.05:\n",
        "    print(\"Reject null hypothesis >> The variances of the samples are different.\")\n",
        "else:\n",
        "    print(\"Fail to reject null hypothesis >> The variances of the samples are same.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LKOcgim7bL65",
        "outputId": "4a851c67-2889-498c-fb2c-214ea946fda9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p_value :0.0285\n",
            "Reject null hypothesis >> The data is not normally distributed\n",
            "p_value :0.4156\n",
            "Fail to reject null hypothesis >> The data is normally distributed\n",
            "p_value :0.1716\n",
            "Fail to reject null hypothesis >> The data is normally distributed\n",
            "p value:0.0012\n",
            "Reject null hypothesis >> The variances of the samples are different.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "F, p_value = stats.kruskal(youtube, instagram, facebook)\n",
        "print(\"p value:%.6f\" % p_value)\n",
        "if p_value <0.05:\n",
        "    print(\"Reject null hypothesis\")\n",
        "else:\n",
        "    print(\"Fail to reject null hypothesis\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_2wpJ_VbSP_",
        "outputId": "cf2f7bf4-4b82-4c75-ba53-57e46d38d805"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p value:0.000015\n",
            "Reject null hypothesis\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "piedpiper=[4.57, 4.55, 5.47, 4.67, 5.41, 5.55, 5.53, 5.63, 3.86, 3.97, 5.44, 3.93, 5.31, 5.17, 4.39, 4.28, 5.25]\n",
        "endframe = [4.27, 3.93, 4.01, 4.07, 3.87, 4. , 4. , 3.72, 4.16, 4.1 , 3.9 , 3.97, 4.08, 3.96, 3.96, 3.77, 4.09]\n",
        "\n",
        "check_normality(piedpiper)\n",
        "check_normality(endframe)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EqPBIJzek2Tn",
        "outputId": "300289a1-d450-4fa0-bef7-bf9d2aa9328f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p_value :0.0304\n",
            "Reject null hypothesis >> The data is not normally distributed\n",
            "p_value :0.9587\n",
            "Fail to reject null hypothesis >> The data is normally distributed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test,pvalue = stats.wilcoxon(endframe,piedpiper) ##alternative default two sided\n",
        "print(\"p-value:%.6f\" %pvalue, \">> one_tailed_pval:%.6f\" %(pvalue/2))\n",
        "\n",
        "test,one_sided_pvalue = stats.wilcoxon(endframe,piedpiper, alternative=\"less\")\n",
        "print(\"one sided pvalue:%.6f\" %(one_sided_pvalue))\n",
        "if pvalue <0.05:\n",
        "    print(\"Reject null hypothesis\")\n",
        "else:\n",
        "    print(\"Fail to recejt null hypothesis\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQ6hXaQ5k2QI",
        "outputId": "7bdf67ac-a2e0-432b-ec1d-ef380aa26298"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p-value:0.000214 >> one_tailed_pval:0.000107\n",
            "one sided pvalue:0.000107\n",
            "Reject null hypothesis\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "method_A=[89.8,89.9,88.6,88.7,89.6,89.7,89.2,89.3]\n",
        "method_B=[90.0,90.1,88.8,88.9,89.9,90.0,89.0,89.2]\n",
        "method_C=[91.5,90.7,90.3,90.4,90.2,90.3,90.2,90.3]\n",
        "check_normality(method_A)\n",
        "check_normality(method_B)\n",
        "check_normality(method_C)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3w-_jyfCnk8P",
        "outputId": "4b57f178-ad26-45cc-e62b-f499c8caad68"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p_value :0.3076\n",
            "Fail to reject null hypothesis >> The data is normally distributed\n",
            "p_value :0.0515\n",
            "Fail to reject null hypothesis >> The data is normally distributed\n",
            "p_value :0.0016\n",
            "Reject null hypothesis >> The data is not normally distributed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stat, pvalue_levene= stats.levene(method_A,method_B,method_C)\n",
        "print(\"p value:%.4f\" % pvalue_levene)\n",
        "if pvalue_levene <0.05:\n",
        "    print(\"Reject null hypothesis >> The variances of the samples are different.\")\n",
        "else:\n",
        "    print(\"Fail to reject null hypothesis >> The variances of the samples are same.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-bqTbUsoFMO",
        "outputId": "75cdfb95-8be5-429e-a8f4-99a51e271bd0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p value:0.1953\n",
            "Fail to reject null hypothesis >> The variances of the samples are same.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "test_stat,p_value = stats.friedmanchisquare(method_A,method_B, method_C)\n",
        "print(\"p value:%.4f\" % p_value)\n",
        "if p_value <0.05:\n",
        "    print(\"Reject null hypothesis\")\n",
        "else:\n",
        "    print(\"Fail to reject null hypothesis\")\n",
        "    \n",
        "print(np.round(np.mean(method_A),2), np.round(np.mean(method_B),2), np.round(np.mean(method_C),2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vMOWXUZto1HX",
        "outputId": "3ae54760-9f23-4329-9d2a-0c125c379fc1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p value:0.0015\n",
            "Reject null hypothesis\n",
            "89.35 89.49 90.49\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zEATYZ0yk2Oh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Jgf7hyhKk2FO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8JYk6PxBk2CK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zmomMzsDk1VM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}